<!--
SPDX-License-Identifier: MIT AND CC-BY-4.0
Copyright (c) 2025 John William Creighton (s243a)
-->

# Chapter 5: Shell Script Generation

## Overview

The shell glue module generates complete, working scripts for AWK, Python, and Bash. These scripts handle:

- Input parsing (TSV, CSV, JSON)
- Field assignment
- Output formatting
- Header handling

## The Shell Glue Module

Located at `src/unifyweaver/glue/shell_glue.pl`:

```prolog
:- module(shell_glue, [
    generate_awk_script/4,      % Complete AWK script
    generate_python_script/4,   % Complete Python script
    generate_bash_script/4,     % Complete Bash script
    generate_pipeline/3         % Pipeline orchestration
]).
```

## AWK Script Generation

### Basic Generation

```prolog
generate_awk_script(
    Logic,      % AWK code for the main block
    Fields,     % Input field names
    Options,    % Configuration
    Script      % Generated script
).
```

### Example: Simple Filter

```prolog
?- generate_awk_script(
    'if (status >= 400) print ip, timestamp, status',
    [ip, timestamp, method, path, status],
    [format(tsv)],
    Script
).
```

Generated:

```awk
#!/usr/bin/awk -f
# Generated by UnifyWeaver shell_glue

BEGIN {
    FS = "\t"
    OFS = "\t"
}

{
    # Assign input fields
    ip = $1
    timestamp = $2
    method = $3
    path = $4
    status = $5

    # User logic
    if (status >= 400) print ip, timestamp, status
}
```

### AWK with Header Skipping

```prolog
generate_awk_script(
    'print name, age * 2',
    [name, age, city],
    [format(tsv), header(true)],
    Script
).
```

Generated:

```awk
#!/usr/bin/awk -f

BEGIN {
    FS = "\t"
    OFS = "\t"
}

NR == 1 {
    # Skip header line
    next
}

{
    name = $1
    age = $2
    city = $3

    print name, age * 2
}
```

### AWK with JSON Output

```prolog
generate_awk_script(
    '',  % Empty - just output
    [name, age],
    [input_format(tsv), output_format(json)],
    Script
).
```

Generated:

```awk
#!/usr/bin/awk -f

BEGIN {
    FS = "\t"
}

{
    name = $1
    age = $2

    # JSON output
    printf "{\"name\":\"%s\",\"age\":%s}\n", name, age
}
```

## Python Script Generation

### Basic Generation

```prolog
generate_python_script(
    Logic,      % Python code for record processing
    Fields,     % Input field names
    Options,    % Configuration
    Script      % Generated script
).
```

### Example: Data Transformation

```prolog
?- generate_python_script(
    'result = {"name": name.upper(), "score": int(value) * 10}',
    [name, value],
    [format(tsv)],
    Script
).
```

Generated:

```python
#!/usr/bin/env python3
"""Generated by UnifyWeaver shell_glue"""

import sys

def read_input():
    for line in sys.stdin:
        fields = line.rstrip('\n').split('\t')
        yield {
            'name': fields[0],
            'value': fields[1]
        }

def write_output(record):
    print('\t'.join(str(v) for v in record.values()))
    sys.stdout.flush()

for record in read_input():
    name = record['name']
    value = record['value']

    # User logic
    result = {"name": name.upper(), "score": int(value) * 10}

    write_output(result)
```

### Python with JSON I/O

```prolog
generate_python_script(
    'result = transform(record)',
    [id, data],
    [input_format(json), output_format(json)],
    Script
).
```

Generated:

```python
#!/usr/bin/env python3
import sys
import json

def read_input():
    for line in sys.stdin:
        yield json.loads(line)

def write_output(record):
    print(json.dumps(record))
    sys.stdout.flush()

for record in read_input():
    id = record['id']
    data = record['data']

    result = transform(record)

    write_output(result)
```

### Python with Error Handling

```prolog
generate_python_script(
    Logic,
    Fields,
    [format(tsv), error_handling(log_continue)],
    Script
).
```

Generated:

```python
#!/usr/bin/env python3
import sys

def read_input():
    for line_num, line in enumerate(sys.stdin, 1):
        try:
            fields = line.rstrip('\n').split('\t')
            yield {'_line': line_num, 'name': fields[0], 'value': fields[1]}
        except IndexError as e:
            print(f"Error on line {line_num}: {e}", file=sys.stderr)

for record in read_input():
    try:
        name = record['name']
        value = record['value']
        # User logic...
    except Exception as e:
        print(f"Processing error on line {record['_line']}: {e}",
              file=sys.stderr)
```

## Bash Script Generation

### Basic Generation

```prolog
generate_bash_script(
    Logic,      % Bash code for record processing
    Fields,     % Input field names
    Options,    # Configuration
    Script      % Generated script
).
```

### Example: Simple Processing

```prolog
?- generate_bash_script(
    'echo "$name: $value"',
    [name, value],
    [format(tsv)],
    Script
).
```

Generated:

```bash
#!/bin/bash
# Generated by UnifyWeaver shell_glue

set -euo pipefail

while IFS=$'\t' read -r name value; do
    # User logic
    echo "$name: $value"
done
```

### Bash with Header Skipping

```prolog
generate_bash_script(
    'printf "%s\t%s\n" "$name" "$((value * 2))"',
    [name, value],
    [format(tsv), header(true)],
    Script
).
```

Generated:

```bash
#!/bin/bash
set -euo pipefail

# Skip header
read -r _header

while IFS=$'\t' read -r name value; do
    printf "%s\t%s\n" "$name" "$((value * 2))"
done
```

## Format Options Reference

### Input/Output Formats

| Option | Values | Default |
|--------|--------|---------|
| `format(F)` | tsv, csv, json | tsv |
| `input_format(F)` | tsv, csv, json | (inherits from format) |
| `output_format(F)` | tsv, csv, json | (inherits from format) |

### Header Options

| Option | Values | Default |
|--------|--------|---------|
| `header(B)` | true, false | false |
| `emit_header(B)` | true, false | false |

### Processing Options

| Option | Values | Default |
|--------|--------|---------|
| `error_handling(E)` | fail, log_continue | fail |
| `buffer(B)` | line, block(N), none | line |

## Complete Example: Log Analysis

Let's build a log analysis script generator:

```prolog
% Generate AWK filter for error logs
generate_error_filter(Script) :-
    generate_awk_script(
        'if ($5 >= 400) print $1, $2, $5, $6',
        [ip, timestamp, method, path, status, bytes],
        [format(tsv)],
        Script
    ).

% Generate Python aggregator
generate_ip_aggregator(Script) :-
    generate_python_script(
        '
from collections import Counter
counts = Counter()

def process(record):
    counts[record["ip"]] += 1

def finish():
    for ip, count in counts.most_common(10):
        print(f"{ip}\t{count}")
',
        [ip, timestamp, status, bytes],
        [format(tsv)],
        Script
    ).
```

## Combining with Pipe Glue

Shell glue uses pipe glue internally:

```prolog
generate_awk_script(Logic, Fields, Options, Script) :-
    % Get format options
    option_or_default(format(Format), Options, tsv),

    % Generate reader
    generate_tsv_reader(awk, Fields, ReaderCode),

    % Generate writer
    generate_tsv_writer(awk, Fields, WriterCode),

    % Combine
    format(atom(Script), '...~w...~w...~w...', [ReaderCode, Logic, WriterCode]).
```

## Target-Specific Features

### AWK Features

- Automatic field splitting (`FS`, `OFS`)
- NR for line numbers
- Pattern-action syntax
- Built-in functions (gsub, split, substr)

### Python Features

- Generator-based streaming
- JSON parsing/serialization
- Error handling with context
- Access to full standard library

### Bash Features

- IFS-based field splitting
- Process substitution
- File descriptor handling
- Integration with system commands

## Performance Tips

### AWK Performance

```awk
# Pre-compile regex in BEGIN
BEGIN {
    regex = "^ERROR"
}
{
    if ($0 ~ regex) print
}
```

### Python Performance

```python
# Use sys.stdout.write for speed
import sys
write = sys.stdout.write

for record in read_input():
    write(f"{record['name']}\t{record['value']}\n")
```

### Bash Performance

```bash
# Avoid subshells in loops
while read -r line; do
    # Direct variable manipulation
    echo "${line^^}"  # Uppercase in bash 4+
done
```

## Chapter Summary

- **AWK scripts** for fast text processing
- **Python scripts** for complex transformations
- **Bash scripts** for system integration
- **Format handling** is automatic
- **Header support** is built-in
- **Error handling** is configurable

## Next Steps

In Chapter 6, we'll combine these scripts into multi-stage pipelines:
- Pipeline orchestration
- Step configuration
- Input/output handling
- Error propagation

## Exercises

1. **AWK generator**: Generate an AWK script that filters CSV records where column 3 > 100.

2. **Python generator**: Generate a Python script that reads JSON, adds a timestamp field, and outputs JSON.

3. **Format conversion**: Generate a script that converts CSV input to JSON output.

4. **Error handling**: Generate a Python script with `log_continue` error handling that logs malformed records.

## Code Examples

See `examples/02-shell-formats/` for:
- `filter.awk` - AWK filtering example
- `transform.py` - Python transformation
- `process.sh` - Bash processing

---

## Navigation

**‚Üê** [Previous: Chapter 4: Pipe Protocols and Data Formats](04_pipe_protocols) | [üìñ Book 7: Cross-Target Glue](./) | [Next: Chapter 6: Shell Pipeline Orchestration ‚Üí](06_shell_pipelines)
