<!--
SPDX-License-Identifier: MIT AND CC-BY-4.0
Copyright (c) 2025 John William Creighton (s243a)
-->

# Chapter 16: Cloud & Enterprise (Phase 7)

Phase 7 extends UnifyWeaver's deployment capabilities to cloud-native environments, providing container orchestration, secrets management, multi-region deployment, and serverless functions.

> **Note**: Phase 7 features are **EXPERIMENTAL**. Tests verify code generation correctness, but actual deployment has not been integration-tested. Always validate generated configurations in your target environment.

## Overview

Phase 7 has three sub-phases:

| Sub-Phase | Focus | Key Features |
|-----------|-------|--------------|
| 7a | Container Deployment | Docker, Kubernetes, Helm |
| 7b | Secrets Management | Vault, AWS, Azure, GCP |
| 7c | Multi-Region & Serverless | Failover, Lambda, GCF, Azure Functions |

## Phase 7a: Container Deployment

### Docker Configuration

Declare Docker settings for your services:

```prolog
:- use_module('src/unifyweaver/glue/deployment_glue').

% Configure Docker for a Python service
:- declare_service(data_processor, [
    target(python),
    port(8080),
    entry_point('main.py')
]).

:- declare_docker_config(data_processor, [
    base_image('python:3.11-slim'),
    workdir('/app'),
    env(['LOG_LEVEL'-'INFO', 'WORKERS'-'4']),
    healthcheck(http('/health')),
    user('appuser')
]).
```

### Dockerfile Generation

Generate optimized Dockerfiles for any target:

```prolog
% Generate Python Dockerfile
?- generate_dockerfile(data_processor, [], Dockerfile).
% Dockerfile = '# Generated by UnifyWeaver - Phase 7a Container Deployment
% # Service: data_processor
%
% FROM python:3.11-slim
%
% WORKDIR /app
%
% # Install dependencies
% COPY requirements.txt .
% RUN pip install --no-cache-dir -r requirements.txt
%
% # Copy application
% COPY . .
%
% ENV LOG_LEVEL=INFO
% ENV WORKERS=4
% USER appuser
% HEALTHCHECK --interval=30s --timeout=5s ...
% EXPOSE 8080
%
% CMD ["python", "main.py"]'
```

UnifyWeaver generates target-appropriate Dockerfiles:

| Target | Features |
|--------|----------|
| Python | Slim base, pip cache optimization |
| Go | Multi-stage build, static binary |
| Rust | Multi-stage build, dependency caching |
| Node.js | npm ci for reproducible builds |
| C#/.NET | SDK build stage, runtime stage |

### Multi-Stage Builds

Go and Rust automatically use multi-stage builds:

```prolog
:- declare_docker_config(api_gateway, [
    multi_stage(true),
    base_image('golang:1.21-alpine'),
    runtime_image('alpine:latest')
]).

?- generate_dockerfile(api_gateway, [], Dockerfile).
% Generates:
% FROM golang:1.21-alpine AS builder
% ... build stage ...
% FROM alpine:latest
% COPY --from=builder /api_gateway .
```

### Docker Compose

Generate multi-service configurations:

```prolog
:- declare_compose_config(my_project, [
    services([
        service(web, [
            build('.'),
            ports(['8080:8080']),
            depends_on([db, cache])
        ]),
        service(db, [
            image('postgres:15'),
            volumes(['pgdata:/var/lib/postgresql/data'])
        ]),
        service(cache, [
            image('redis:7-alpine')
        ])
    ]),
    volumes([pgdata-[]]),
    networks([app_network-[driver(bridge)]])
]).

?- generate_docker_compose(my_project, [], Yaml).
```

### Kubernetes Deployment

Generate Kubernetes manifests:

```prolog
:- declare_k8s_config(data_processor, [
    namespace('production'),
    replicas(3),
    image('myregistry/data-processor:v1.2.0'),
    resources([
        requests([cpu('100m'), memory('256Mi')]),
        limits([cpu('500m'), memory('512Mi')])
    ]),
    ports([8080]),
    env_from([
        configmap('app-config'),
        secret('app-secrets')
    ])
]).

% Generate deployment manifest
?- generate_k8s_deployment(data_processor, [], Manifest).

% Generate service manifest
?- generate_k8s_service(data_processor, [type('ClusterIP')], Service).

% Generate ingress
?- generate_k8s_ingress(data_processor, [
    host('api.example.com'),
    tls(true)
], Ingress).
```

### Container Registry Operations

```prolog
:- declare_registry(my_registry, [
    type(ecr),
    url('123456789.dkr.ecr.us-east-1.amazonaws.com'),
    region('us-east-1')
]).

% Generate login command
?- login_registry(my_registry, [], Command).
% Command = 'aws ecr get-login-password --region us-east-1 | docker login ...'

% Build and push image
?- build_docker_image(data_processor, [tag('v1.2.0')], BuildCmd).
?- push_docker_image(data_processor, [registry(my_registry)], PushCmd).
```

## Phase 7b: Secrets Management

### HashiCorp Vault

```prolog
:- declare_vault_config(production_vault, [
    url('https://vault.example.com:8200'),
    auth_method(kubernetes),
    k8s_role('data-processor'),
    namespace('prod'),
    mount_path('secret')
]).

% Generate secret read command
?- generate_vault_read(production_vault, 'app/database', [field(password)], Cmd).
% Cmd = 'VAULT_TOKEN=... vault kv get -namespace=prod -field=password secret/data/app/database'

% Generate Vault Agent config for automatic injection
?- generate_vault_agent_config(data_processor, [vault_source(production_vault)], Config).
```

### AWS Secrets Manager

```prolog
:- declare_aws_secrets_config(aws_secrets, [
    region('us-east-1'),
    profile('production')
]).

% Read entire secret
?- generate_aws_secret_read(aws_secrets, 'prod/db-credentials', [], Cmd).

% Read specific key from JSON secret
?- generate_aws_secret_read(aws_secrets, 'prod/db-credentials', [key(password)], Cmd).
% Cmd = 'aws secretsmanager get-secret-value ... | jq -r '.SecretString | fromjson | .password''
```

### Azure Key Vault

```prolog
:- declare_azure_keyvault_config(azure_kv, [
    vault_name('mycompany-prod-kv'),
    subscription('xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx')
]).

?- generate_azure_secret_read(azure_kv, 'DatabasePassword', [], Cmd).
% Cmd = 'az keyvault secret show --vault-name mycompany-prod-kv --name DatabasePassword --query value -o tsv'
```

### GCP Secret Manager

```prolog
:- declare_gcp_secrets_config(gcp_secrets, [
    project('my-project-123'),
    impersonate_sa('secrets-reader@my-project.iam.gserviceaccount.com')
]).

?- generate_gcp_secret_read(gcp_secrets, 'database-password', [version('latest')], Cmd).
% Cmd = 'gcloud secrets versions access latest --secret=database-password --project=my-project-123 ...'
```

### Service Secret Bindings

Bind secrets to services for injection:

```prolog
:- declare_service_secrets(data_processor, [
    secret('DB_PASSWORD', production_vault, 'app/database', password),
    secret('API_KEY', aws_secrets, 'prod/api-keys', primary_key),
    file_secret('/etc/ssl/cert.pem', production_vault, 'pki/cert')
]).

% Generate environment injection script
?- generate_secret_env_script(data_processor, [], Script).

% Generate Kubernetes Secret manifest (for development/testing)
?- generate_k8s_secret(data_processor, [placeholder(true)], Manifest).

% Generate ExternalSecret for production (uses external-secrets operator)
?- generate_k8s_external_secret(data_processor, [backend(vault)], Manifest).
```

### Unified Secret Access

The unified API works with any backend:

```prolog
% Resolve secret from configured source
?- resolve_secret(production_vault, 'app/database', [field(password)], Result).
% Result = vault_read(Command)

?- resolve_secret(aws_secrets, 'prod/credentials', [key(api_key)], Result).
% Result = aws_read(Command)

% List available secrets
?- list_secrets(production_vault, [path('app/')], Secrets).
```

## Phase 7c: Multi-Region Deployment

### Region Configuration

```prolog
:- declare_region(us_east, [
    provider(aws),
    region_id('us-east-1'),
    latency_zone('NA'),
    availability_zones(['us-east-1a', 'us-east-1b', 'us-east-1c'])
]).

:- declare_region(eu_west, [
    provider(aws),
    region_id('eu-west-1'),
    latency_zone('EU'),
    availability_zones(['eu-west-1a', 'eu-west-1b'])
]).

:- declare_region(ap_southeast, [
    provider(aws),
    region_id('ap-southeast-1'),
    latency_zone('APAC')
]).
```

### Service Region Assignment

```prolog
:- declare_service_regions(data_processor, [
    primary(us_east),
    secondary([eu_west, ap_southeast]),
    active_active(false),
    replication([async, lag_threshold(5000)])
]).
```

### Failover Policies

```prolog
:- declare_failover_policy(data_processor, [
    strategy(priority),          % or: latency, weighted, geolocation
    health_check([
        protocol(http),
        path('/health'),
        interval(30),
        threshold(3)
    ]),
    failover_threshold(3),
    recovery_threshold(2),
    dns_ttl(60)
]).

% Select best region based on policy
?- select_region(data_processor, [prefer_healthy(true)], Region).
% Region = us_east (if healthy)

% Select by latency zone
?- select_region(data_processor, [source_location('EU')], Region).
% Region = eu_west
```

### Failover Commands

```prolog
% Generate failover commands
?- failover_to_region(data_processor, eu_west, Result).
% Result = failover_commands([
%     '# Failover data_processor from us_east to eu_west',
%     'aws route53 change-resource-record-sets ...'
% ])
```

### Multi-Region Deployment

```prolog
% Deploy to specific region
?- deploy_to_region(data_processor, us_east, [], Result).
% Result = deploy_commands(us_east, [
%     'export AWS_REGION=us-east-1',
%     'aws ecs update-service --cluster data_processor-cluster ...'
% ])

% Deploy to all regions
?- deploy_to_all_regions(data_processor, [], Results).
% Results = [deploy_commands(us_east, ...), deploy_commands(eu_west, ...), ...]

% Check region status
?- region_status(data_processor, us_east, Status).
% Status = status_command(us_east, 'aws ecs describe-services ...')
```

### DNS Traffic Management

```prolog
:- declare_traffic_policy(data_processor, [
    dns_provider(route53),
    routing_policy(failover),
    health_check_id('$HEALTH_CHECK_ID')
]).

% Generate Route53 failover configuration
?- generate_route53_config(data_processor, [
    hosted_zone('$ZONE_ID'),
    domain('api.example.com')
], Config).

% Generate Cloudflare configuration
?- generate_cloudflare_config(data_processor, [domain('api.example.com')], Config).
```

### Terraform Integration

```prolog
?- generate_region_config(data_processor, [format(terraform)], Config).
% Config = '# Multi-region configuration for data_processor
%
% module "data_processor_primary" {
%   source = "./modules/service"
%   region = "us_east"
%   is_primary = true
% }
%
% module "data_processor_eu_west" {
%   source = "./modules/service"
%   region = "eu_west"
%   is_primary = false
% }
% ...'
```

## Phase 7c: Cloud Functions (Serverless)

### AWS Lambda

```prolog
:- declare_lambda_config(process_events, [
    runtime('python3.11'),
    handler('index.handler'),
    memory(512),
    timeout(30),
    role('$LAMBDA_ROLE_ARN'),
    environment([
        'LOG_LEVEL'-'INFO',
        'TABLE_NAME'-'events'
    ])
]).

% Generate Lambda handler boilerplate
?- generate_lambda_function(process_events, [], Package).
% Package = lambda_package(process_events, 'python3.11', HandlerCode)

% Generate deployment commands
?- generate_lambda_deploy(process_events, [region('us-east-1')], Commands).
% Commands = [
%     '# Deploy Lambda function: process_events',
%     'cd process_events && zip -r function.zip .',
%     'aws lambda create-function --function-name process_events ...',
%     '# Or update existing function:',
%     'aws lambda update-function-code ...'
% ]

% Generate SAM template
?- generate_sam_template(process_events, [description('Event processor')], Template).
```

### Google Cloud Functions

```prolog
:- declare_gcf_config(process_events, [
    runtime('python311'),
    entry_point('main'),
    memory(256),
    timeout(60),
    region('us-central1'),
    trigger(http)
]).

% Generate deployment commands
?- generate_gcf_deploy(process_events, [project('my-project')], Commands).
% Commands = [
%     '# Deploy Google Cloud Function: process_events',
%     'gcloud functions deploy process_events --runtime python311 ...'
% ]

% PubSub triggered function
:- declare_gcf_config(handle_messages, [
    runtime('nodejs20'),
    entry_point('handleMessage'),
    trigger(pubsub)
]).
```

### Azure Functions

```prolog
:- declare_azure_func_config(process_events, [
    runtime('python'),
    version('3.11'),
    os('linux'),
    resource_group('$AZURE_RG'),
    storage_account('$AZURE_STORAGE')
]).

?- generate_azure_func_deploy(process_events, [location('eastus')], Commands).
% Commands = [
%     '# Deploy Azure Function: process_events',
%     'az functionapp create --name process_events ...',
%     'func azure functionapp publish process_events'
% ]
```

### Unified Serverless API

The unified API works across all providers:

```prolog
% Deploy to any configured provider
?- deploy_function(process_events, [region('us-east-1')], Result).
% Result = lambda_deploy(Commands)  % or gcf_deploy, azure_deploy

% Invoke function
?- invoke_function(process_events, '{"event": "test"}', [], Result).
% Result = invoke_command(aws, 'aws lambda invoke ...')

% Get function logs
?- function_logs(process_events, [tail(50)], Logs).
% Logs = log_command(aws, 'aws logs tail /aws/lambda/process_events ...')
```

### API Gateway Integration

```prolog
:- declare_api_gateway(my_api, [
    provider(aws),
    description('My API Gateway'),
    endpoints([
        endpoint('/users', 'GET', list_users),
        endpoint('/users', 'POST', create_user),
        endpoint('/users/{id}', 'GET', get_user)
    ]),
    cors([
        origins(['*']),
        methods(['GET', 'POST', 'OPTIONS'])
    ])
]).

% Generate API Gateway config (Swagger/OpenAPI)
?- generate_api_gateway_config(my_api, [], Config).

% Generate OpenAPI 3.0 spec
?- generate_openapi_spec(my_api, [version('3.0.0')], Spec).
```

## Complete Example: Multi-Cloud Deployment

Here's a complete example deploying a service across AWS and GCP with automatic failover:

```prolog
:- use_module('src/unifyweaver/glue/deployment_glue').

%% Service definition
:- declare_service(global_api, [
    target(go),
    port(8080)
]).

%% Container configuration
:- declare_docker_config(global_api, [
    multi_stage(true),
    base_image('golang:1.21-alpine'),
    runtime_image('gcr.io/distroless/static:nonroot'),
    healthcheck(http('/healthz'))
]).

%% Kubernetes configuration
:- declare_k8s_config(global_api, [
    replicas(3),
    resources([
        requests([cpu('100m'), memory('128Mi')]),
        limits([cpu('1'), memory('512Mi')])
    ])
]).

%% Secrets
:- declare_vault_config(vault, [
    url('https://vault.example.com:8200'),
    auth_method(kubernetes)
]).

:- declare_service_secrets(global_api, [
    secret('DB_PASSWORD', vault, 'prod/database', password),
    secret('JWT_SECRET', vault, 'prod/auth', jwt_key)
]).

%% Regions
:- declare_region(aws_primary, [provider(aws), region_id('us-east-1')]).
:- declare_region(gcp_backup, [provider(gcp), region_id('us-central1')]).

:- declare_service_regions(global_api, [
    primary(aws_primary),
    secondary([gcp_backup])
]).

:- declare_failover_policy(global_api, [
    strategy(priority),
    failover_threshold(3)
]).

%% Deploy everything
deploy_global_api :-
    % Generate Dockerfile
    generate_dockerfile(global_api, [], Dockerfile),
    write('=== Dockerfile ==='), nl,
    write(Dockerfile), nl, nl,

    % Generate K8s manifests
    generate_k8s_deployment(global_api, [], Deployment),
    write('=== K8s Deployment ==='), nl,
    write(Deployment), nl, nl,

    % Generate secret injection
    generate_k8s_external_secret(global_api, [backend(vault)], ExternalSecret),
    write('=== ExternalSecret ==='), nl,
    write(ExternalSecret), nl, nl,

    % Deploy to all regions
    deploy_to_all_regions(global_api, [], RegionResults),
    write('=== Region Deployments ==='), nl,
    forall(member(R, RegionResults), (write(R), nl)).
```

## Best Practices

### Container Security

1. **Use distroless/minimal base images** for production
2. **Run as non-root user** with `user(appuser)`
3. **Multi-stage builds** to minimize attack surface
4. **Scan images** before pushing to registry

### Secrets Management

1. **Never commit secrets** - use placeholders in K8s Secrets
2. **Use ExternalSecrets** in production for dynamic secret injection
3. **Rotate secrets regularly** - Vault Agent handles this automatically
4. **Principle of least privilege** - each service gets only its secrets

### Multi-Region

1. **Health checks are critical** - configure appropriate thresholds
2. **Test failover regularly** - don't wait for production incidents
3. **Consider data replication** - async vs sync trade-offs
4. **DNS TTL matters** - lower TTL = faster failover, more queries

### Serverless

1. **Cold start optimization** - minimize dependencies, use provisioned concurrency
2. **Timeout settings** - set appropriate timeouts for each function
3. **Memory = CPU** - higher memory allocates more CPU on Lambda/GCF
4. **Idempotent handlers** - functions may be retried

## Testing Phase 7

All Phase 7 tests verify code generation:

```bash
swipl -g "['tests/glue/test_deployment_glue.pl'], run_all_tests, halt"
```

Test breakdown:
- **Phase 7a**: 21 tests (Docker, Kubernetes, Registry)
- **Phase 7b**: 19 tests (Vault, AWS, Azure, GCP secrets)
- **Phase 7c**: 22 tests (Multi-region, Lambda, GCF, Azure Functions)

## Chapter Summary

Phase 7 provides enterprise-grade deployment capabilities:

| Feature | Predicates | Use Case |
|---------|------------|----------|
| Docker | `generate_dockerfile/3`, `generate_docker_compose/3` | Containerization |
| Kubernetes | `generate_k8s_deployment/3`, `generate_k8s_service/3` | Orchestration |
| Vault | `generate_vault_read/4`, `generate_vault_agent_config/3` | HashiCorp secrets |
| AWS/Azure/GCP | `generate_aws_secret_read/4`, etc. | Cloud secrets |
| Multi-Region | `deploy_to_region/4`, `failover_to_region/3` | Geographic distribution |
| Lambda | `generate_lambda_deploy/3`, `deploy_function/3` | AWS serverless |
| GCF | `generate_gcf_deploy/3` | GCP serverless |
| Azure Functions | `generate_azure_func_deploy/3` | Azure serverless |
| API Gateway | `generate_api_gateway_config/3`, `generate_openapi_spec/3` | API management |

## Next Steps

After this book, continue to **Book: Workflow** for:
- Complete application orchestration
- CI/CD pipeline integration
- Production monitoring dashboards
- Operational runbooks

## Exercises

1. **Docker Multi-Stage**: Generate a Dockerfile for a Rust service with multi-stage build. What's the size difference vs single-stage?

2. **Secret Rotation**: Design a secret rotation strategy using Vault Agent. What happens during rotation?

3. **Failover Testing**: Set up a 3-region deployment with `strategy(latency)`. How would you test failover?

4. **Serverless Pipeline**: Create an event processing pipeline: S3 trigger -> Lambda -> DynamoDB. Generate all configurations.

5. **Hybrid Deployment**: Design a system where the API runs on Kubernetes but background jobs run on Lambda. How do they share secrets?

---

## Navigation

**â†** [Previous: Chapter 15: Production Deployment (Phase 6)](15_deployment_production) | [ğŸ“– Book 7: Cross-Target Glue](./) | [Next: Book 8: Security & Firewall â†’](../book-08-security-firewall/)
